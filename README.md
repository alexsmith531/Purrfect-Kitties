# Purrfect Kitties
Written by: 
* [Alex Smith](https://github.com/alexsmith531)
* [Brian Carlson](https://github.com/TheRobotCarlson)
* [Luke Miles](https://github.com/qpwo)

For the [RevolutionUC](https://revolutionuc.com/) Fall 2016 hackathon.

## Purpose of this project
Orginally, our goal was to read brainwaves from the [Muse](http://www.choosemuse.com/developer-kit/), 
go through a training session of blinks to switch pictures, head nods or shakes to acknowledge you like or dislike a picture.
Recording the data from the Muse about the user's brain activity and using machine learning techniques, 
our goal was to be able to correlate certain signals with the user liking a picture and be able to predict if a user liked a picture
solely off of the user's brain activity. All of this was to be done through an Android app.

## What it does right now
Right now it just establishes a bluetooth connection between the Android device and the Muse, then  
displays nod and blink data from the Muse and changes pictures for each blink.

## Significant hurdles we ran into
* None of us had ever used the Muse or programmed Android apps before
* One of our team members hadn't done any programming outside of the beginning freshman course
* One of our team members primarily worked with Python

## Things we learned
* How to use Java for computation
* How to use XML for UI design
* How to use Muse's [Android SDK](http://developer.choosemuse.com/android/getting-started-with-libmuse-android)
* Using brainwave data is a complicated, but extremely interesting problem!
* That making Android apps is exciting!


## Future possibilities
Seeing as none of us own a Muse nor possess the money to purchase one, this project will likely be on hold indefinitely 
or at least until the next time we have the opportunity to work with the Muse. We would all love to work on it again in the future, though.
